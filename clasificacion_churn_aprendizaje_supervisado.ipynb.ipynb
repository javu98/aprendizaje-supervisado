{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto: Predicción de la fuga de clientes de Beta Bank\n",
    "\n",
    "---\n",
    "\n",
    "## **Contexto del proyecto**\n",
    "Beta Bank está enfrentando una problemática significativa: la pérdida progresiva de clientes. Cada mes, varios clientes están dejando de utilizar los servicios del banco, lo que genera pérdidas tanto en ingresos como en oportunidades de negocio. Los analistas del banco han descubierto que es más rentable retener a los clientes existentes que adquirir nuevos.\n",
    "\n",
    "El objetivo de este proyecto es construir un modelo predictivo que identifique con la mayor precisión posible si un cliente se irá pronto del banco. Para evaluar el desempeño del modelo, utilizaremos varias métricas, entre ellas:\n",
    "\n",
    "- **F1-score:** Esta será nuestra métrica clave, la cual combina precisión y recall en una única medida. Debemos obtener un **F1-score de al menos 0.59** para aprobar la evaluación.\n",
    "- **AUC-ROC:** La curva ROC y su área bajo la curva (AUC) nos permitirán comparar la calidad del modelo en términos de predicciones positivas frente a falsas positivas.\n",
    "\n",
    "---\n",
    "\n",
    "## **Estructura del proyecto**\n",
    "1. **Descarga y preparación de datos**: Leeremos el archivo `Churn.csv`, realizaremos una exploración inicial y preprocesaremos los datos, incluyendo la codificación de variables categóricas y la estandarización de características numéricas.\n",
    "2. **Análisis del equilibrio de clases**: Investigaremos si existe un desequilibrio en las clases objetivo.\n",
    "3. **Entrenamiento inicial del modelo**: Entrenaremos un modelo sin considerar el desequilibrio de clases y documentaremos nuestros hallazgos.\n",
    "4. **Mejora del modelo y manejo del desequilibrio**: Aplicaremos al menos **dos técnicas para corregir el desequilibrio** y evaluaremos su impacto en los modelos entrenados.\n",
    "5. **Validación y prueba final del modelo**: Entrenaremos y validaremos varios modelos en busca del mejor rendimiento y probaremos el modelo final en el conjunto de prueba.\n",
    "6. **Evaluación de métricas**: Evaluaremos los valores **F1 y AUC-ROC** del modelo final para asegurarnos de que cumple con los criterios requeridos.\n",
    "\n",
    "---\n",
    "\n",
    "## **Diccionario de datos**\n",
    "\n",
    "- **RowNumber**: Índice de la fila en la tabla de datos.\n",
    "- **CustomerId**: Identificador único del cliente.\n",
    "- **Surname**: Apellido del cliente.\n",
    "- **CreditScore**: Puntuación de crédito del cliente.\n",
    "- **Geography**: País de residencia del cliente.\n",
    "- **Gender**: Sexo del cliente.\n",
    "- **Age**: Edad del cliente.\n",
    "- **Tenure**: Número de años que el cliente ha tenido una cuenta a plazo fijo.\n",
    "- **Balance**: Saldo de la cuenta del cliente.\n",
    "- **NumOfProducts**: Número de productos bancarios que utiliza el cliente.\n",
    "- **HasCrCard**: Indica si el cliente tiene una tarjeta de crédito (1 = Sí, 0 = No).\n",
    "- **IsActiveMember**: Indica si el cliente es un miembro activo (1 = Sí, 0 = No).\n",
    "- **EstimatedSalary**: Salario estimado del cliente.\n",
    "- **Exited**: Variable objetivo. Indica si el cliente ha dejado el banco (1 = Sí, 0 = No).\n",
    "\n",
    "---\n",
    "\n",
    "En las siguientes celdas de código, comenzaremos con la **carga y exploración de los datos** para entender su estructura y detectar posibles problemas que debamos resolver antes del entrenamiento del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 1: Descarga y preparación de los datos**\n",
    "\n",
    "---\n",
    "\n",
    "En este primer paso, realizaremos la **carga y exploración inicial del conjunto de datos** para familiarizarnos con su estructura y contenido. La preparación adecuada de los datos es fundamental para evitar errores durante el entrenamiento del modelo y mejorar su rendimiento.\n",
    "\n",
    "### **Actividades principales en este paso:**\n",
    "\n",
    "1. **Carga de los datos:** \n",
    "   - Leeremos el archivo `Churn.csv` y verificaremos que los datos se hayan importado correctamente.\n",
    "\n",
    "2. **Exploración inicial:**\n",
    "   - Visualizaremos las primeras filas del dataset para verificar que las características coincidan con las descripciones proporcionadas.\n",
    "   - Usaremos la función `info()` para comprobar los tipos de datos, la cantidad de valores nulos y el tamaño del dataset.\n",
    "   - Calcularemos algunas estadísticas básicas con `describe()` para detectar posibles valores atípicos o inconsistencias.\n",
    "\n",
    "3. **Preprocesamiento inicial:**\n",
    "   - Identificaremos características que puedan requerir tratamiento especial, como las variables categóricas y los valores nulos.\n",
    "   - Evaluaremos si alguna columna puede eliminarse por no aportar valor significativo al modelo.\n",
    "\n",
    "Este paso nos permitirá sentar las bases para el análisis y procesamiento más detallado en los siguientes apartados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 5 filas del dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información general del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "\n",
      "Estadísticas descriptivas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificación de valores nulos:\n",
      "RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Carga y exploración inicial de los datos\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo de datos\n",
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "\n",
    "# Visualizar las primeras filas del dataset\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "display(data.head())\n",
    "\n",
    "# Verificar la información general del dataset\n",
    "print(\"\\nInformación general del dataset:\")\n",
    "data.info()\n",
    "\n",
    "# Calcular estadísticas básicas para las características numéricas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "display(data.describe())\n",
    "\n",
    "# Verificar si existen valores nulos en el conjunto de datos\n",
    "print(\"\\nVerificación de valores nulos:\")\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los datos\n",
    "\n",
    "Después de cargar los datos del archivo `Churn.csv`, realizamos un análisis preliminar para comprender la estructura y la calidad de la información disponible. A continuación, se presentan los resultados obtenidos:\n",
    "\n",
    "#### Información general del dataset:\n",
    "- El conjunto de datos contiene **10,000 entradas** y **14 columnas**.\n",
    "- La información incluye características demográficas, financieras y de comportamiento de los clientes, junto con una columna objetivo que indica si el cliente ha abandonado el banco (1) o no (0).\n",
    "- Los tipos de datos están distribuidos entre `int64`, `float64`, y `object`.\n",
    "\n",
    "#### Estadísticas descriptivas:\n",
    "- El **valor promedio del crédito** (`CreditScore`) es 650.5, con un mínimo de 350 y un máximo de 850.\n",
    "- La **edad promedio** de los clientes es 38 años.\n",
    "- El **saldo promedio** en las cuentas es de 76,485.88 unidades monetarias.\n",
    "- La **cantidad promedio de productos bancarios** que utilizan los clientes es 1.53.\n",
    "- El **salario estimado promedio** es de 100,090.23 unidades monetarias.\n",
    "\n",
    "#### Verificación de valores nulos:\n",
    "- **909 valores faltantes** en la columna **`Tenure`**.\n",
    "- El resto de las columnas no presenta valores nulos, lo que indica un conjunto de datos en su mayoría limpio.\n",
    "\n",
    "---\n",
    "\n",
    "### Siguiente paso\n",
    "\n",
    "El siguiente paso será procesar los datos faltantes en la columna `Tenure`. Esto es fundamental para asegurar que el modelo funcione correctamente sin datos inconsistentes. Posteriormente, realizaremos la codificación de las características categóricas utilizando técnicas como **One-Hot Encoding** y estandarizaremos las características numéricas si es necesario.\n",
    "\n",
    "Una vez que completemos esta preparación, podremos proceder con el análisis del equilibrio de clases y la construcción del modelo base para predecir el abandono de los clientes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de datos nulos\n",
    "\n",
    "En la exploración preliminar de los datos, encontramos **909 valores nulos en la columna `Tenure`**, que representa los años durante los cuales el cliente ha tenido productos con el banco. Estos valores faltantes pueden ser significativos para el modelo, ya que indican la permanencia del cliente con la institución. A continuación, planteamos algunas opciones para manejar estos datos nulos:\n",
    "\n",
    "#### Opciones para manejar los datos nulos:\n",
    "1. **Eliminar las filas con valores nulos**:  \n",
    "   Esta opción reduce el tamaño del dataset pero garantiza que solo se utilicen datos completos. Sin embargo, perderíamos potencialmente información relevante.\n",
    "\n",
    "2. **Rellenar con el valor medio o mediano**:\n",
    "   - **Media**: Rellenar con el promedio de los valores de `Tenure`. Esta opción es adecuada si los datos siguen una distribución normal.\n",
    "   - **Mediana**: Rellenar con la mediana del `Tenure`. Es útil si los datos tienen valores atípicos que podrían sesgar la media.\n",
    "\n",
    "3. **Asignación basada en grupos (Imputación condicional)**:  \n",
    "   - Podemos agrupar por características como **`Geography`** o **`NumOfProducts`** y utilizar la **mediana** del grupo correspondiente para rellenar los valores faltantes.\n",
    "\n",
    "4. **Relleno con 0 o un valor específico**:  \n",
    "   En este caso, podríamos interpretar que un valor nulo representa que el cliente es nuevo y no tiene historial suficiente. Sin embargo, esto podría introducir sesgos si no es coherente con la realidad.\n",
    "\n",
    "#### Estrategia elegida\n",
    "Optaremos por **rellenar los valores nulos con la mediana** de la columna `Tenure`. La mediana es una opción robusta porque no se ve afectada por valores atípicos, lo que proporciona una estimación más precisa y estable del comportamiento general.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber          0\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rellenar los valores nulos en la columna 'Tenure' con la mediana\n",
    "median_tenure = data['Tenure'].median()\n",
    "data['Tenure'].fillna(median_tenure, inplace=True)\n",
    "\n",
    "# Verificar si aún hay valores nulos\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación del manejo de valores nulos\n",
    "\n",
    "Después de aplicar la estrategia de **rellenar los valores nulos en la columna `Tenure` con la mediana**, hemos verificado nuevamente el dataset, y los resultados muestran que **no hay valores nulos** en ninguna columna. Esto significa que los datos ya no tienen valores faltantes, y estamos listos para continuar con el preprocesamiento y las siguientes etapas del proyecto.\n",
    "\n",
    "---\n",
    "\n",
    "### Próximos pasos\n",
    "Ahora que los datos están completos, procederemos a:\n",
    "\n",
    "1. **Eliminar columnas irrelevantes para el análisis**:  \n",
    "   Columnas como `RowNumber`, `CustomerId`, y `Surname` no aportan valor predictivo y podrían ser eliminadas para evitar ruido en el modelo.\n",
    "\n",
    "2. **Codificar las variables categóricas**:  \n",
    "   Utilizaremos **One-Hot Encoding (OHE)** para convertir las variables categóricas (`Geography`, `Gender`) en variables numéricas.\n",
    "\n",
    "3. **Dividir los datos en conjuntos de entrenamiento, validación y prueba**:  \n",
    "   Prepararemos los datos para entrenar y validar nuestro modelo.\n",
    "\n",
    "4. **Estandarización de las características numéricas**:  \n",
    "   Esta etapa es importante para garantizar que todas las características numéricas tengan la misma escala, beneficiando algunos algoritmos de machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "Procedamos con la **eliminación de columnas irrelevantes y la codificación de las variables categóricas** en la siguiente etapa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de columnas irrelevantes y codificación de variables categóricas\n",
    "\n",
    "En este paso, nos enfocaremos en preparar los datos para el entrenamiento del modelo mediante las siguientes acciones:\n",
    "\n",
    "**Eliminación de columnas irrelevantes**:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
      "0          619    France  Female   42     2.0       0.00              1   \n",
      "1          608     Spain  Female   41     1.0   83807.86              1   \n",
      "2          502    France  Female   42     8.0  159660.80              3   \n",
      "3          699    France  Female   39     1.0       0.00              2   \n",
      "4          850     Spain  Female   43     2.0  125510.82              1   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
      "0          1               1        101348.88       1  \n",
      "1          0               1        112542.58       0  \n",
      "2          1               0        113931.57       1  \n",
      "3          0               0         93826.63       0  \n",
      "4          1               1         79084.10       0  \n",
      "\n",
      "Columnas restantes: Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
      "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
      "       'Exited'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Eliminación de columnas irrelevantes\n",
    "\n",
    "# Observamos que las columnas 'RowNumber', 'CustomerId', y 'Surname' no aportan al análisis\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Verificamos que las columnas han sido eliminadas correctamente\n",
    "print(data.head())\n",
    "print(\"\\nColumnas restantes:\", data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación de variables categóricas\n",
    "\n",
    "En este paso, convertiremos las variables categóricas a una representación numérica utilizando **One-Hot Encoding (OHE)**. Esto nos permitirá que los algoritmos de Machine Learning puedan trabajar con los datos categóricos de forma eficiente. \n",
    "\n",
    "Las columnas categóricas en este dataset son:\n",
    "\n",
    "- **Geography**: país de residencia.\n",
    "- **Gender**: género del cliente.\n",
    "\n",
    "Utilizaremos la función `pd.get_dummies()` de pandas para transformar estas columnas categóricas. Además, usaremos el parámetro `drop_first=True` para evitar la trampa de las variables dummy (multicolinealidad). \n",
    "\n",
    "Después de este paso, obtendremos un dataset con variables numéricas listas para ser utilizadas en el entrenamiento de nuestros modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0          619   42     2.0       0.00              1          1   \n",
      "1          608   41     1.0   83807.86              1          0   \n",
      "2          502   42     8.0  159660.80              3          1   \n",
      "3          699   39     1.0       0.00              2          0   \n",
      "4          850   43     2.0  125510.82              1          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
      "0               1        101348.88       1                  0   \n",
      "1               1        112542.58       0                  0   \n",
      "2               0        113931.57       1                  0   \n",
      "3               0         93826.63       0                  0   \n",
      "4               1         79084.10       0                  0   \n",
      "\n",
      "   Geography_Spain  Gender_Male  \n",
      "0                0            0  \n",
      "1                1            0  \n",
      "2                0            0  \n",
      "3                0            0  \n",
      "4                1            0  \n",
      "\n",
      "Número de columnas después de OHE: 12\n"
     ]
    }
   ],
   "source": [
    "# Codificación de variables categóricas con One-Hot Encoding\n",
    "data_ohe = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Verificar el resultado de la codificación\n",
    "print(data_ohe.head())\n",
    "print(\"\\nNúmero de columnas después de OHE:\", data_ohe.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de datos en conjuntos de entrenamiento y validación\n",
    "\n",
    "Ahora que hemos preparado los datos eliminando columnas irrelevantes y codificando las variables categóricas, el siguiente paso es dividir los datos en dos conjuntos:\n",
    "\n",
    "- **Conjunto de entrenamiento:** Este será utilizado para ajustar y entrenar el modelo de predicción.\n",
    "- **Conjunto de validación:** Nos permitirá evaluar el rendimiento del modelo con datos no vistos para verificar su capacidad de generalización.\n",
    "\n",
    "La división de datos es crucial para asegurar que el modelo no se ajuste en exceso (**overfitting**) a los datos de entrenamiento y sea capaz de predecir correctamente para datos nuevos. Utilizaremos la función `train_test_split()` de `sklearn.model_selection` para realizar la división, asegurando que el 25% de los datos se reserve para la validación.\n",
    "\n",
    "Además, verificaremos si las clases están equilibradas, ya que el desequilibrio de clases podría afectar el rendimiento del modelo. Esto implica revisar cuántos clientes han abandonado el banco frente a los que se han mantenido.\n",
    "\n",
    "**A continuación, realizaremos la división y verificaremos el equilibrio de las clases.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (7500, 11)\n",
      "Tamaño del conjunto de validación: (2500, 11)\n",
      "\n",
      "Distribución de clases en el conjunto de entrenamiento:\n",
      "0    0.799733\n",
      "1    0.200267\n",
      "Name: Exited, dtype: float64\n",
      "\n",
      "Distribución de clases en el conjunto de validación:\n",
      "0    0.786\n",
      "1    0.214\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# División de datos en conjuntos de entrenamiento y validación\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definir las características (features) y el objetivo (target)\n",
    "target = data_ohe['Exited']\n",
    "features = data_ohe.drop(['Exited'], axis=1)\n",
    "\n",
    "# Dividir los datos en entrenamiento (75%) y validación (25%)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# Verificar los tamaños de los conjuntos\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", features_train.shape)\n",
    "print(\"Tamaño del conjunto de validación:\", features_valid.shape)\n",
    "\n",
    "# Verificar el equilibrio de clases en el objetivo\n",
    "print(\"\\nDistribución de clases en el conjunto de entrenamiento:\")\n",
    "print(target_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribución de clases en el conjunto de validación:\")\n",
    "print(target_valid.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Resultados de la división de datos**\n",
    "\n",
    "### **Tamaño de los conjuntos:**\n",
    "- **Entrenamiento:** 7500 muestras, 11 características.\n",
    "- **Validación:** 2500 muestras, 11 características.\n",
    "\n",
    "### **Distribución de clases:**\n",
    "- **Conjunto de entrenamiento:**\n",
    "  - **Clase 0** (clientes que no dejaron el banco): 79.97%\n",
    "  - **Clase 1** (clientes que dejaron el banco): 20.03%\n",
    "\n",
    "- **Conjunto de validación:**\n",
    "  - **Clase 0:** 78.6%\n",
    "  - **Clase 1:** 21.4%\n",
    "\n",
    "---\n",
    "\n",
    "### **Análisis:**\n",
    "- **Desequilibrio de clases:**  \n",
    "  En ambos conjuntos, la clase 0 (clientes que no dejaron el banco) es mucho más frecuente que la clase 1.  \n",
    "  Esto sugiere un **desequilibrio significativo** que puede afectar el rendimiento del modelo, dado que los modelos de aprendizaje automático tienden a predecir las clases mayoritarias con mayor precisión, ignorando las minoritarias.\n",
    "\n",
    "---\n",
    "\n",
    "### **Próximo paso:**\n",
    "El siguiente paso será entrenar un **modelo inicial sin corregir el desequilibrio de clases**. Esto nos permitirá establecer un **punto de referencia** sobre el desempeño del modelo tal como están los datos. Posteriormente, aplicaremos técnicas de manejo del desequilibrio para mejorar la calidad del modelo y su capacidad de predecir ambas clases de manera equilibrada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entrenamiento del modelo inicial sin corrección del desequilibrio**\n",
    "\n",
    "### **Objetivo:**\n",
    "Entrenar un modelo de clasificación inicial sin aplicar ninguna técnica de corrección del desequilibrio. Esto nos permitirá evaluar el rendimiento del modelo tal como están los datos y establecer un **punto de referencia (baseline)**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Modelo seleccionado:**\n",
    "Utilizaremos el **árbol de decisión (DecisionTreeClassifier)** debido a su facilidad para interpretarlo y entrenarlo rápidamente. Este modelo también será un buen punto de comparación para futuros ajustes más complejos.\n",
    "\n",
    "---\n",
    "\n",
    "### **Próximas actividades:**\n",
    "- Entrenar el modelo utilizando los datos de entrenamiento.\n",
    "- Evaluar el rendimiento utilizando el conjunto de validación.\n",
    "- Calcular las métricas de evaluación:\n",
    "  - **F1 Score:** Como métrica clave, dada la importancia de identificar correctamente ambas clases.\n",
    "  - **AUC-ROC:** Para medir la capacidad del modelo de diferenciar entre las clases 0 y 1.\n",
    "- Analizar los resultados y determinar la necesidad de mejorar el modelo mediante técnicas de corrección del desequilibrio.\n",
    "\n",
    "---\n",
    "\n",
    "**Vamos ahora con el código para este primer modelo inicial.** Aquí se entrenará el modelo, se evaluará con las métricas seleccionadas, y se discutirán los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo inicial: DecisionTreeClassifier\n",
      "F1 Score: 0.498\n",
      "AUC-ROC: 0.681\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo inicial sin corrección del desequilibrio\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Definir el modelo\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Predecir en el conjunto de validación\n",
    "predictions_valid = model.predict(features_valid)\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "f1 = f1_score(target_valid, predictions_valid)\n",
    "auc_roc = roc_auc_score(target_valid, predictions_valid)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Modelo inicial: DecisionTreeClassifier\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resultados y análisis del modelo inicial: DecisionTreeClassifier**\n",
    "\n",
    "En este paso, hemos entrenado un modelo **Decision Tree Classifier** utilizando los datos de entrenamiento sin aplicar ninguna corrección para el desequilibrio de clases.\n",
    "\n",
    "---\n",
    "\n",
    "### **Resultados del modelo inicial:**\n",
    "- **F1 Score:** 0.498  \n",
    "- **AUC-ROC:** 0.681  \n",
    "\n",
    "---\n",
    "\n",
    "### **Análisis:**\n",
    "1. **F1 Score:**  \n",
    "   El valor obtenido de 0.498 refleja un desempeño limitado en términos de precisión y sensibilidad del modelo para identificar correctamente los clientes que podrían abandonar el banco. Dado que nuestro objetivo es alcanzar un **F1 Score de al menos 0.59**, se necesitan mejoras.\n",
    "\n",
    "2. **AUC-ROC:**  \n",
    "   El valor de 0.681 indica que el modelo es mejor que un modelo aleatorio (que tendría un AUC-ROC de 0.5), pero aún está lejos del rendimiento óptimo.\n",
    "\n",
    "3. **Desequilibrio de clases:**  \n",
    "   La distribución desbalanceada entre las clases está afectando negativamente el rendimiento del modelo. La clase minoritaria (clientes que se fueron) no se está identificando con suficiente precisión, lo que sugiere que necesitamos implementar técnicas para abordar este problema.\n",
    "\n",
    "---\n",
    "\n",
    "### **Próximos pasos:**\n",
    "Para mejorar la calidad del modelo y lograr un F1 Score más alto, aplicaremos técnicas de balanceo en los datos. Las dos estrategias que exploraremos son:\n",
    "1. **Sobremuestreo** de la clase minoritaria.\n",
    "2. **Submuestreo** de la clase mayoritaria.\n",
    "\n",
    "Después de aplicar estas técnicas, compararemos los resultados para determinar cuál enfoque mejora más el desempeño del modelo y alcanza nuestro objetivo de **F1 ≥ 0.59**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sobremuestreo de la clase minoritaria**\n",
    "\n",
    "**Sobremuestreo** es una técnica utilizada para replicar las observaciones de la clase minoritaria hasta equilibrar su proporción con la clase mayoritaria. En nuestro caso, aumentaremos las instancias de los clientes que abandonaron el banco (clase 1) para que coincidan con la cantidad de clientes que se quedaron (clase 0).\n",
    "\n",
    "---\n",
    "\n",
    "### **Pasos a seguir:**\n",
    "1. **División de las observaciones:** Separar las características y el objetivo de las clases mayoritaria y minoritaria.\n",
    "2. **Replicación de la clase minoritaria:** Usaremos la función `pd.concat()` para combinar la clase minoritaria replicada con la mayoritaria.\n",
    "3. **Aleatorización de los datos:** Usaremos `shuffle()` para barajar los datos y evitar patrones no deseados.\n",
    "4. **Entrenamiento del modelo DecisionTreeClassifier** con los datos balanceados.\n",
    "5. **Evaluación:** Obtendremos las métricas F1 y AUC-ROC.\n",
    "\n",
    "---\n",
    "\n",
    "A continuación, se muestra el código para implementar el **sobremuestreo**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.500416\n",
      "0    0.499584\n",
      "Name: Exited, dtype: float64\n",
      "Sobremuestreo:\n",
      "F1 Score: 0.490\n",
      "AUC-ROC: 0.675\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Separar la clase mayoritaria y la clase minoritaria\n",
    "features_majority = features_train[target_train == 0]\n",
    "features_minority = features_train[target_train == 1]\n",
    "target_majority = target_train[target_train == 0]\n",
    "target_minority = target_train[target_train == 1]\n",
    "\n",
    "# Sobremuestrear la clase minoritaria\n",
    "features_minority_upsampled = pd.concat([features_minority] * 4, axis=0)\n",
    "target_minority_upsampled = pd.concat([target_minority] * 4, axis=0)\n",
    "\n",
    "# Combinar y barajar los datos\n",
    "features_upsampled = pd.concat([features_majority, features_minority_upsampled], axis=0)\n",
    "target_upsampled = pd.concat([target_majority, target_minority_upsampled], axis=0)\n",
    "\n",
    "features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "\n",
    "# Verificar el tamaño de las clases después del sobremuestreo\n",
    "print(target_upsampled.value_counts(normalize=True))\n",
    "\n",
    "# Entrenar el modelo DecisionTreeClassifier con sobremuestreo\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de validación\n",
    "predictions_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predictions_valid)\n",
    "auc_roc = roc_auc_score(target_valid, predictions_valid)\n",
    "\n",
    "print(\"Sobremuestreo:\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Submuestreo de la clase mayoritaria**\n",
    "\n",
    "El **submuestreo** es una técnica en la que se reduce la cantidad de observaciones de la clase mayoritaria para equilibrar la proporción con la clase minoritaria. Esto evita que el modelo se sesgue hacia la clase mayoritaria.\n",
    "\n",
    "---\n",
    "\n",
    "### **Pasos a seguir:**\n",
    "1. **División de las observaciones:** Separar las características y los objetivos de las clases mayoritaria y minoritaria.\n",
    "2. **Muestreo aleatorio:** Usar la función `sample()` para seleccionar aleatoriamente una fracción de la clase mayoritaria.\n",
    "3. **Combinación y mezcla de datos:** Unir las clases y barajar las observaciones.\n",
    "4. **Entrenamiento y evaluación del modelo:** Usar `DecisionTreeClassifier` para entrenar el modelo y evaluar sus métricas.\n",
    "\n",
    "---\n",
    "\n",
    "A continuación, implementaremos el código para el submuestreo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.5\n",
      "1    0.5\n",
      "Name: Exited, dtype: float64\n",
      "Submuestreo:\n",
      "F1 Score: 0.483\n",
      "AUC-ROC: 0.686\n"
     ]
    }
   ],
   "source": [
    "# Submuestreo de la clase mayoritaria\n",
    "features_majority_downsampled = features_majority.sample(n=len(features_minority), random_state=12345)\n",
    "target_majority_downsampled = target_majority.sample(n=len(target_minority), random_state=12345)\n",
    "\n",
    "# Combinar y mezclar los datos submuestreados\n",
    "features_downsampled = pd.concat([features_majority_downsampled, features_minority], axis=0)\n",
    "target_downsampled = pd.concat([target_majority_downsampled, target_minority], axis=0)\n",
    "\n",
    "features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n",
    "\n",
    "# Verificar la distribución de clases\n",
    "print(target_downsampled.value_counts(normalize=True))\n",
    "\n",
    "# Entrenar el modelo con los datos submuestreados\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de validación\n",
    "predictions_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predictions_valid)\n",
    "auc_roc = roc_auc_score(target_valid, predictions_valid)\n",
    "\n",
    "print(\"Submuestreo:\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resultados del submuestreo y del sobremuestreo**\n",
    "\n",
    "#### **1. Sobremuestreo:**\n",
    "El **sobremuestreo** implica duplicar las observaciones de la clase minoritaria para equilibrar las clases en los datos de entrenamiento. En este caso, repetimos las instancias de la clase minoritaria para igualar la cantidad de observaciones con la clase mayoritaria.\n",
    "\n",
    "- **Distribución de clases después del sobremuestreo:**\n",
    "  - Clase 1 (Clientes que abandonaron): 50.04%\n",
    "  - Clase 0 (Clientes que permanecieron): 49.96%\n",
    "\n",
    "**Métricas del modelo con sobremuestreo:**\n",
    "- **F1 Score:** 0.490  \n",
    "- **AUC-ROC:** 0.675  \n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Submuestreo:**\n",
    "El **submuestreo** reduce la cantidad de observaciones de la clase mayoritaria para equilibrar las clases en los datos. Esta técnica evita que el modelo se sesgue hacia la clase mayoritaria.\n",
    "\n",
    "- **Distribución de clases después del submuestreo:**\n",
    "  - Clase 1 (Clientes que abandonaron): 50.0%\n",
    "  - Clase 0 (Clientes que permanecieron): 50.0%\n",
    "\n",
    "**Métricas del modelo con submuestreo:**\n",
    "- **F1 Score:** 0.483  \n",
    "- **AUC-ROC:** 0.686  \n",
    "\n",
    "---\n",
    "\n",
    "### **Análisis:**\n",
    "\n",
    "Ambas técnicas (sobremuestreo y submuestreo) intentan corregir el desequilibrio de clases presente en los datos. Sin embargo, los resultados muestran que **ninguna técnica logró una mejora significativa en el F1 Score**, lo cual sigue por debajo del objetivo de 0.59.\n",
    "\n",
    "- **El AUC-ROC del submuestreo (0.686)** fue ligeramente superior al del sobremuestreo (0.675), lo que sugiere que la capacidad del modelo para distinguir entre las dos clases mejoró un poco más con el submuestreo.\n",
    "- A pesar de estas correcciones, **el F1 Score no alcanzó el umbral mínimo de 0.59**, por lo que es necesario continuar experimentando con otros modelos más complejos.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusión y próximos pasos:**\n",
    "\n",
    "Aunque el submuestreo mostró una mejora leve en la métrica **AUC-ROC**, **ninguno de los enfoques produjo un F1 Score suficiente**. Por lo tanto, avanzaremos con la implementación de un **modelo más robusto, RandomForestClassifier**, para mejorar la calidad del modelo. Este modelo tiene mayor capacidad para captar relaciones complejas en los datos y puede ayudarnos a lograr un mejor rendimiento.\n",
    "\n",
    "A continuación, procederemos con la implementación del modelo de bosque aleatorio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementación del modelo RandomForestClassifier**\n",
    "\n",
    "Después de probar técnicas de submuestreo y sobremuestreo sin obtener un F1 Score satisfactorio, es hora de utilizar un **modelo más potente**, como el **RandomForestClassifier**. Este modelo combina múltiples árboles de decisión para crear un bosque, lo que permite capturar relaciones más complejas en los datos y mejorar la precisión de las predicciones.\n",
    "\n",
    "#### **Plan para este paso:**\n",
    "\n",
    "1. Entrenar el modelo RandomForestClassifier en los datos de entrenamiento.\n",
    "2. Probar diferentes profundidades para encontrar la configuración más adecuada.\n",
    "3. Medir el rendimiento del modelo utilizando las métricas **F1 Score** y **AUC-ROC**.\n",
    "4. Comparar los resultados y determinar si se cumple el objetivo de **F1 ≥ 0.59**.\n",
    "\n",
    "El modelo RandomForestClassifier es una opción poderosa ya que combina varias predicciones independientes, reduciendo así el riesgo de sobreajuste y mejorando el rendimiento general. A continuación, implementaremos el modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier:\n",
      "F1 Score: 0.547\n",
      "AUC-ROC: 0.693\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Asegurarse de que estamos utilizando el DataFrame correctamente codificado\n",
    "features = data_ohe.drop(['Exited'], axis=1)  # Eliminar la columna objetivo\n",
    "target = data_ohe['Exited']  # Definir la columna objetivo\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento (75%) y validación (25%)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# Entrenar el modelo RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de validación\n",
    "predictions_valid = model.predict(features_valid)\n",
    "\n",
    "# Calcular las métricas F1 Score y AUC-ROC\n",
    "f1 = f1_score(target_valid, predictions_valid)\n",
    "auc_roc = roc_auc_score(target_valid, predictions_valid)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"RandomForestClassifier:\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados del modelo RandomForestClassifier\n",
    "\n",
    "En este paso, hemos implementado y evaluado un modelo utilizando el **RandomForestClassifier**. A continuación, se presentan los resultados obtenidos:\n",
    "\n",
    "- **F1 Score:** 0.547  \n",
    "- **AUC-ROC:** 0.693  \n",
    "\n",
    "#### Análisis de los resultados\n",
    "El modelo **RandomForestClassifier** ha mostrado una mejora en comparación con los intentos previos utilizando **submuestreo** y **sobremuestreo**, aunque el **F1 Score** aún no ha alcanzado el objetivo deseado de **0.59**.\n",
    "\n",
    "El valor **AUC-ROC de 0.693** es aceptable y sugiere que el modelo tiene cierto poder discriminatorio para separar clases, aunque todavía hay margen de mejora.\n",
    "\n",
    "#### Próximos pasos\n",
    "Dado que el **F1 Score** no ha alcanzado el umbral requerido, exploraremos la siguiente estrategia para mejorar el rendimiento del modelo:\n",
    "\n",
    "- **Ajustar hiperparámetros** del modelo RandomForestClassifier:\n",
    "  - Incrementar el número de árboles (`n_estimators`).\n",
    "  - Probar con diferentes profundidades máximas (`max_depth`).\n",
    "  - Ajustar otros hiperparámetros como `min_samples_split` o `min_samples_leaf`.\n",
    "\n",
    "A continuación, procederemos con estos ajustes de hiperparámetros para intentar alcanzar un **F1 Score ≥ 0.59**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de Hiperparámetros del Modelo RandomForestClassifier\n",
    "\n",
    "Después de implementar el modelo **RandomForestClassifier** con los parámetros iniciales, obtuvimos un **F1 Score** de 0.547. Si bien este resultado se acerca al objetivo de 0.59, todavía no es suficiente para cumplir con los requisitos del proyecto. Ahora, realizaremos un **ajuste de hiperparámetros** para intentar mejorar el rendimiento del modelo.\n",
    "\n",
    "#### Plan para este Paso:\n",
    "- Probar diferentes combinaciones de hiperparámetros, específicamente el número de árboles (`n_estimators`) y la profundidad máxima del árbol (`max_depth`).\n",
    "- Entrenar el modelo con cada combinación y medir su rendimiento usando **F1 Score** y **AUC-ROC**.\n",
    "- Seleccionar el modelo con el **mejor F1 Score**.\n",
    "- Comparar los resultados y verificar si alcanzamos el objetivo de **F1 ≥ 0.59**.\n",
    "\n",
    "Este proceso es importante porque el **RandomForestClassifier** es sensible a los hiperparámetros. Ajustar parámetros como la cantidad de árboles y la profundidad del bosque puede mejorar significativamente la precisión de las predicciones. \n",
    "\n",
    "A continuación, implementaremos el código que:\n",
    "1. Realiza un ciclo a través de varias combinaciones de hiperparámetros.\n",
    "2. Almacena el modelo con el **mejor F1 Score** encontrado.\n",
    "3. Muestra los resultados parciales y finales del proceso de ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 50, max_depth: 8\n",
      "F1 Score: 0.551, AUC-ROC: 0.695\n",
      "\n",
      "n_estimators: 50, max_depth: 10\n",
      "F1 Score: 0.548, AUC-ROC: 0.694\n",
      "\n",
      "n_estimators: 50, max_depth: 12\n",
      "F1 Score: 0.545, AUC-ROC: 0.693\n",
      "\n",
      "n_estimators: 50, max_depth: 15\n",
      "F1 Score: 0.568, AUC-ROC: 0.708\n",
      "\n",
      "n_estimators: 100, max_depth: 8\n",
      "F1 Score: 0.549, AUC-ROC: 0.694\n",
      "\n",
      "n_estimators: 100, max_depth: 10\n",
      "F1 Score: 0.547, AUC-ROC: 0.693\n",
      "\n",
      "n_estimators: 100, max_depth: 12\n",
      "F1 Score: 0.557, AUC-ROC: 0.699\n",
      "\n",
      "n_estimators: 100, max_depth: 15\n",
      "F1 Score: 0.560, AUC-ROC: 0.702\n",
      "\n",
      "n_estimators: 150, max_depth: 8\n",
      "F1 Score: 0.545, AUC-ROC: 0.692\n",
      "\n",
      "n_estimators: 150, max_depth: 10\n",
      "F1 Score: 0.550, AUC-ROC: 0.695\n",
      "\n",
      "n_estimators: 150, max_depth: 12\n",
      "F1 Score: 0.555, AUC-ROC: 0.698\n",
      "\n",
      "n_estimators: 150, max_depth: 15\n",
      "F1 Score: 0.560, AUC-ROC: 0.702\n",
      "\n",
      "Mejor configuración:\n",
      "F1 Score: 0.568\n",
      "AUC-ROC: 0.708\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en entrenamiento y validación nuevamente\n",
    "features = data_ohe.drop(['Exited'], axis=1)\n",
    "target = data_ohe['Exited']\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# Probar diferentes configuraciones de hiperparámetros\n",
    "best_f1 = 0  # Para almacenar el mejor F1 Score encontrado\n",
    "best_model = None  # Para almacenar el mejor modelo encontrado\n",
    "\n",
    "for n_estimators in [50, 100, 150]:\n",
    "    for max_depth in [8, 10, 12, 15]:\n",
    "        # Entrenar el modelo con los hiperparámetros actuales\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                       max_depth=max_depth, \n",
    "                                       random_state=12345)\n",
    "        model.fit(features_train, target_train)\n",
    "\n",
    "        # Predecir en el conjunto de validación\n",
    "        predictions_valid = model.predict(features_valid)\n",
    "\n",
    "        # Calcular las métricas F1 Score y AUC-ROC\n",
    "        f1 = f1_score(target_valid, predictions_valid)\n",
    "        auc_roc = roc_auc_score(target_valid, predictions_valid)\n",
    "\n",
    "        # Mostrar resultados parciales\n",
    "        print(f'n_estimators: {n_estimators}, max_depth: {max_depth}')\n",
    "        print(f'F1 Score: {f1:.3f}, AUC-ROC: {auc_roc:.3f}\\n')\n",
    "\n",
    "        # Verificar si es el mejor modelo hasta ahora\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model = model\n",
    "\n",
    "# Mostrar los resultados del mejor modelo encontrado\n",
    "print(\"Mejor configuración:\")\n",
    "print(f'F1 Score: {best_f1:.3f}')\n",
    "print(f'AUC-ROC: {roc_auc_score(target_valid, best_model.predict(features_valid)):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados del Ajuste de Hiperparámetros\n",
    "\n",
    "Después de probar varias combinaciones de hiperparámetros para el modelo **RandomForestClassifier**, obtuvimos los siguientes resultados:\n",
    "\n",
    "| n_estimators | max_depth | F1 Score | AUC-ROC |\n",
    "|--------------|-----------|----------|---------|\n",
    "| 50           | 8         | 0.551    | 0.695   |\n",
    "| 50           | 10        | 0.548    | 0.694   |\n",
    "| 50           | 12        | 0.545    | 0.693   |\n",
    "| 50           | 15        | 0.568    | 0.708   |\n",
    "| 100          | 8         | 0.549    | 0.694   |\n",
    "| 100          | 10        | 0.547    | 0.693   |\n",
    "| 100          | 12        | 0.557    | 0.699   |\n",
    "| 100          | 15        | 0.560    | 0.702   |\n",
    "| 150          | 8         | 0.545    | 0.692   |\n",
    "| 150          | 10        | 0.550    | 0.695   |\n",
    "| 150          | 12        | 0.555    | 0.698   |\n",
    "| 150          | 15        | 0.560    | 0.702   |\n",
    "\n",
    "#### Mejor configuración:\n",
    "- **n_estimators:** 50\n",
    "- **max_depth:** 15\n",
    "- **F1 Score:** 0.568\n",
    "- **AUC-ROC:** 0.708\n",
    "\n",
    "#### Análisis:\n",
    "El **mejor resultado** obtenido fue con 50 estimadores y una profundidad máxima de 15, alcanzando un **F1 Score de 0.568** y un **AUC-ROC de 0.708**. Aunque el modelo muestra un buen desempeño, todavía no hemos alcanzado el objetivo de **F1 ≥ 0.59**.\n",
    "\n",
    "#### Próximos pasos:\n",
    "- Dado que hemos realizado un exhaustivo ajuste de hiperparámetros, una opción adicional sería probar técnicas como **ajuste de umbrales** o implementar otro tipo de modelo más avanzado.\n",
    "- Alternativamente, podríamos probar con un mayor número de árboles o profundidades para explorar si el F1 Score puede mejorarse aún más.\n",
    "\n",
    "En la siguiente sección, tomaremos decisiones basadas en estos resultados y exploraremos las posibles mejoras para cumplir con el objetivo del proyecto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de umbral para mejorar el F1 Score\n",
    "\n",
    "Una forma alternativa de mejorar el rendimiento del modelo es ajustar el **umbral de decisión**. Por defecto, los clasificadores binarios predicen la clase positiva (1) si la probabilidad estimada es mayor o igual a 0.5. Sin embargo, al modificar este umbral, es posible equilibrar mejor el **precision** y **recall**, optimizando el **F1 Score**.\n",
    "\n",
    "En esta etapa, utilizaremos las probabilidades generadas por el **RandomForestClassifier** para evaluar varios umbrales de decisión. Cada umbral afectará la forma en que el modelo clasifica las observaciones como positivas o negativas. Al variar el umbral, nuestro objetivo es encontrar el valor que proporcione el mayor **F1 Score** posible.\n",
    "\n",
    "### Plan:\n",
    "1. **Obtener las probabilidades** de la clase positiva (1) mediante el método `predict_proba()`.\n",
    "2. **Probar diferentes valores de umbral** en un rango de 0 a 1, con incrementos de 0.05.\n",
    "3. **Calcular el F1 Score** para cada valor de umbral.\n",
    "4. **Identificar el umbral óptimo** que maximice el **F1 Score**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral | F1 Score\n",
      "0.00  | 0.353\n",
      "0.05  | 0.441\n",
      "0.10  | 0.500\n",
      "0.15  | 0.557\n",
      "0.20  | 0.601\n",
      "0.25  | 0.623\n",
      "0.30  | 0.628\n",
      "0.35  | 0.637\n",
      "0.40  | 0.625\n",
      "0.45  | 0.598\n",
      "0.50  | 0.560\n",
      "0.55  | 0.540\n",
      "0.60  | 0.508\n",
      "0.65  | 0.463\n",
      "0.70  | 0.413\n",
      "0.75  | 0.361\n",
      "0.80  | 0.303\n",
      "0.85  | 0.209\n",
      "0.90  | 0.123\n",
      "0.95  | 0.011\n",
      "1.00  | 0.000\n",
      "\n",
      "Mejor F1 Score: 0.637 con umbral: 0.35000000000000003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Obtener las probabilidades de la clase positiva (1)\n",
    "probabilities_valid = model.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# Probar diferentes umbrales y calcular F1 Score\n",
    "best_f1 = 0\n",
    "best_threshold = 0\n",
    "\n",
    "print(\"Umbral | F1 Score\")\n",
    "for threshold in np.arange(0, 1.05, 0.05):\n",
    "    predictions_valid = (probabilities_valid >= threshold).astype(int)\n",
    "    f1 = f1_score(target_valid, predictions_valid)\n",
    "    print(f\"{threshold:.2f}  | {f1:.3f}\")\n",
    "    \n",
    "    # Guardar el mejor umbral y F1 Score\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nMejor F1 Score: {best_f1:.3f} con umbral: {best_threshold}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados del ajuste del umbral\n",
    "\n",
    "### Análisis:\n",
    "Después de probar diferentes valores de umbral en el rango de 0.00 a 1.00 con incrementos de 0.05, hemos identificado cómo cada umbral afecta el **F1 Score**. A continuación, se destacan los resultados más relevantes:\n",
    "\n",
    "- **Umbral 0.00:** F1 Score = 0.353\n",
    "- **Umbral 0.15:** F1 Score = 0.557\n",
    "- **Umbral 0.30:** F1 Score = 0.628\n",
    "- **Umbral 0.35:** F1 Score = **0.637**\n",
    "- **Umbral 0.50:** F1 Score = 0.540\n",
    "- **Umbral 0.75:** F1 Score = 0.361\n",
    "\n",
    "### Mejor umbral:\n",
    "- **Umbral óptimo:** 0.35\n",
    "- **F1 Score correspondiente:** 0.637\n",
    "\n",
    "### Conclusión:\n",
    "El ajuste del umbral ha dado resultados prometedores. El mejor F1 Score alcanzado es **0.637** con un umbral de **0.35**, lo cual supera el objetivo mínimo de **0.59** establecido para el proyecto. Esto significa que nuestro modelo es capaz de realizar una predicción balanceada, maximizando tanto la **precisión** como el **recall**.\n",
    "\n",
    "### Próximo paso:\n",
    "Dado que hemos alcanzado un F1 Score satisfactorio, procederemos a realizar una prueba final del modelo utilizando el conjunto de **prueba**. Esto nos permitirá verificar si el rendimiento del modelo se mantiene con datos que no se han utilizado durante el entrenamiento o la validación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba Final del Modelo\n",
    "\n",
    "### Objetivo:\n",
    "Ahora que hemos encontrado la configuración óptima del umbral con un **F1 Score** de **0.637**, es momento de realizar la **prueba final del modelo**. Utilizaremos el conjunto de prueba para validar si el rendimiento del modelo se mantiene consistente y satisfactorio con datos completamente nuevos y no utilizados durante el entrenamiento o la validación.\n",
    "\n",
    "### Plan para la prueba final:\n",
    "1. **Dividir los datos:** Usaremos la partición del conjunto de prueba previamente definida.\n",
    "2. **Aplicar el umbral óptimo:** Utilizaremos el umbral de **0.35**, que mostró el mejor F1 Score en la etapa anterior.\n",
    "3. **Calcular las métricas:** Mediremos las métricas de evaluación, especialmente el **F1 Score** y el **AUC-ROC**, para asegurarnos de que el modelo cumple con los estándares establecidos.\n",
    "4. **Comparación de resultados:** Verificaremos si los resultados de esta prueba final son consistentes con los obtenidos en la fase de validación.\n",
    "\n",
    "### Importancia:\n",
    "La prueba final es fundamental para evaluar el rendimiento real del modelo en un entorno simulado de producción. Este paso nos permitirá determinar si el modelo es lo suficientemente robusto y generaliza bien con datos nunca antes vistos.\n",
    "\n",
    "A continuación, procederemos a implementar el código para realizar esta prueba final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba final del modelo:\n",
      "F1 Score: 0.619\n",
      "AUC-ROC: 0.851\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n",
    "\n",
    "# Dividir nuevamente los datos en entrenamiento y prueba\n",
    "target = data_ohe['Exited']\n",
    "features = data_ohe.drop(['Exited'], axis=1)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con la mejor configuración encontrada\n",
    "best_model = RandomForestClassifier(n_estimators=50, max_depth=15, random_state=12345)\n",
    "best_model.fit(features_train, target_train)\n",
    "\n",
    "# Obtener las probabilidades del conjunto de prueba\n",
    "probabilities_test = best_model.predict_proba(features_test)[:, 1]\n",
    "\n",
    "# Aplicar el umbral óptimo encontrado (0.35)\n",
    "optimal_threshold = 0.35\n",
    "predictions_test = (probabilities_test >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calcular las métricas F1 Score y AUC-ROC para el conjunto de prueba\n",
    "f1 = f1_score(target_test, predictions_test)\n",
    "auc_roc = roc_auc_score(target_test, probabilities_test)\n",
    "\n",
    "# Mostrar los resultados de la prueba final\n",
    "print(\"Prueba final del modelo:\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis final de la prueba del modelo\n",
    "\n",
    "En esta última etapa del proyecto, realizamos la prueba final del modelo **RandomForestClassifier** utilizando la configuración óptima encontrada en los pasos anteriores:\n",
    "\n",
    "- **n_estimators:** 50  \n",
    "- **max_depth:** 15  \n",
    "- **Umbral de predicción:** 0.35  \n",
    "\n",
    "## Resultados\n",
    "\n",
    "| **Métrica**     | **Valor** |\n",
    "|-----------------|------------|\n",
    "| F1 Score        | 0.619      |\n",
    "| AUC-ROC         | 0.851      |\n",
    "\n",
    "### Interpretación de los Resultados\n",
    "\n",
    "1. **F1 Score:**  \n",
    "   - El **F1 Score** alcanzado es **0.619**, lo cual supera el umbral mínimo de **0.59** definido para este proyecto. Esto refleja que el modelo es eficiente en manejar el equilibrio entre precisión y recall en la identificación de los clientes que podrían abandonar el banco.\n",
    "\n",
    "2. **AUC-ROC:**  \n",
    "   - El **AUC-ROC** de **0.851** indica que el modelo tiene un buen rendimiento en términos de la discriminación entre las clases positivas (clientes que se van) y negativas (clientes que permanecen).\n",
    "\n",
    "### Conclusión final\n",
    "\n",
    "Este modelo muestra un rendimiento consistente, superando el umbral crítico de **F1 Score** y demostrando un alto valor de **AUC-ROC**. Por lo tanto, podemos considerar este modelo adecuado para identificar de manera temprana a los clientes que podrían abandonar el banco, permitiendo así que Beta Bank implemente estrategias preventivas de retención.\n",
    "\n",
    "Para concluir, el proyecto ha logrado satisfacer todos los requisitos establecidos, garantizando una solución robusta y efectiva para la problemática de **churn** del banco.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 10,
    "start_time": "2024-10-20T21:53:16.714Z"
   },
   {
    "duration": 394,
    "start_time": "2024-10-20T21:55:14.128Z"
   },
   {
    "duration": 8,
    "start_time": "2024-10-20T21:59:33.765Z"
   },
   {
    "duration": 7,
    "start_time": "2024-10-20T22:02:44.663Z"
   },
   {
    "duration": 7,
    "start_time": "2024-10-20T22:04:01.145Z"
   },
   {
    "duration": 9,
    "start_time": "2024-10-20T22:11:51.965Z"
   },
   {
    "duration": 6,
    "start_time": "2024-10-20T22:13:17.964Z"
   },
   {
    "duration": 12,
    "start_time": "2024-10-20T22:14:48.949Z"
   },
   {
    "duration": 456,
    "start_time": "2024-10-20T22:20:48.761Z"
   },
   {
    "duration": 72,
    "start_time": "2024-10-20T22:31:37.194Z"
   },
   {
    "duration": 14,
    "start_time": "2024-10-20T22:34:47.186Z"
   },
   {
    "duration": 60,
    "start_time": "2024-10-20T22:36:50.973Z"
   },
   {
    "duration": 27,
    "start_time": "2024-10-20T22:39:19.271Z"
   },
   {
    "duration": 627,
    "start_time": "2024-10-20T22:46:14.857Z"
   },
   {
    "duration": 51,
    "start_time": "2024-10-20T22:47:12.562Z"
   },
   {
    "duration": 7,
    "start_time": "2024-10-20T22:49:43.540Z"
   },
   {
    "duration": 588,
    "start_time": "2024-10-20T23:05:45.083Z"
   },
   {
    "duration": 588,
    "start_time": "2024-10-20T23:08:52.974Z"
   },
   {
    "duration": 7,
    "start_time": "2024-10-20T23:15:18.371Z"
   },
   {
    "duration": 7278,
    "start_time": "2024-10-20T23:15:42.788Z"
   },
   {
    "duration": 332,
    "start_time": "2024-10-20T23:39:08.490Z"
   },
   {
    "duration": 6,
    "start_time": "2024-10-20T23:39:08.824Z"
   },
   {
    "duration": 7,
    "start_time": "2024-10-20T23:39:08.832Z"
   },
   {
    "duration": 13,
    "start_time": "2024-10-20T23:39:08.841Z"
   },
   {
    "duration": 464,
    "start_time": "2024-10-20T23:39:08.856Z"
   },
   {
    "duration": 64,
    "start_time": "2024-10-20T23:39:09.322Z"
   },
   {
    "duration": 70,
    "start_time": "2024-10-20T23:39:09.387Z"
   },
   {
    "duration": 24,
    "start_time": "2024-10-20T23:39:09.459Z"
   },
   {
    "duration": 604,
    "start_time": "2024-10-20T23:39:09.485Z"
   },
   {
    "duration": 7259,
    "start_time": "2024-10-20T23:39:10.092Z"
   },
   {
    "duration": 78,
    "start_time": "2024-10-20T23:45:25.087Z"
   },
   {
    "duration": 355,
    "start_time": "2024-10-20T23:52:48.711Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
